{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10 Python Scripts to Automate Your Daily Problems.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIECkkZXoEFPaXa47rXsIw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://python.plainenglish.io/10-python-scripts-to-automate-your-daily-problems-936cdbf1bd82)"
      ],
      "metadata": {
        "id": "gJT4dwGnwtQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Send Discord Webhooks"
      ],
      "metadata": {
        "id": "zkWCipH_wqfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Send Discord Webhooks\n",
        "# pip install discord-webhook\n",
        "\n",
        "from discord_webhook import DiscordWebhook\n",
        "\n",
        "# Send Simple Webhook\n",
        "hook = DiscordWebhook(url='Discord webhook api', content=\"Hello Medium\")\n",
        "hook.execute()\n",
        "\n",
        "# Send Multiple Webhooks\n",
        "url = [\"webhook_api1, webhook_api2\"]\n",
        "hook = DiscordWebhook(url=url, content=\"Hello Medium\")\n",
        "hook.execute()\n",
        "\n",
        "# Send Embed Webhook\n",
        "hook = DiscordWebhook(url='Discord webhook api', content=\"Hello Medium\")\n",
        "hook.add_embed(title=\"Embed Title\", description=\"Embed Description\")\n",
        "hook.execute()\n",
        "\n",
        "# Send File Webhook\n",
        "hook = DiscordWebhook(url='Discord webhook api', content=\"Hello Medium\")\n",
        "hook.add_file(file_path=\"file_path\")\n",
        "hook.execute()\n",
        "\n",
        "# Delete Webhook\n",
        "hook = DiscordWebhook(url='Discord webhook api', content=\"Hello Medium\")\n",
        "web = hook.execute()\n",
        "hook.delete(web)"
      ],
      "metadata": {
        "id": "vopvwJZ_wpbW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bulk Email Sender"
      ],
      "metadata": {
        "id": "BdZN_ELYwiLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bulk Email Sender\n",
        "\n",
        "import smtplib as smtp\n",
        "from email.message import EmailMessage\n",
        "\n",
        "emails = [\"test1@email.com\", \"test2@email.com\"]\n",
        "Email = \"myemail@test.com\"\n",
        "Pass = \"mypassword\"\n",
        "\n",
        "E_msg = EmailMessage()\n",
        "E_msg['Subject'] = \"Test Email\"\n",
        "E_msg['From'] = Email\n",
        "E_msg['To'] = emails\n",
        "E_msg.set_content(\"This is a test email\")\n",
        "\n",
        "with smtp.SMTP_SSL('smtp.gmail.com', 465) as smtp:\n",
        "    smtp.login(Email, Pass)\n",
        "    smtp.send_message(E_msg)"
      ],
      "metadata": {
        "id": "ZSmGfFggwkPX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Network Speed"
      ],
      "metadata": {
        "id": "20SKfrNgwa2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Network Speedc\n",
        "# pip install speedtest-cli\n",
        "\n",
        "import speedtest as sp\n",
        "\n",
        "# Test Download Speed\n",
        "def test_download():\n",
        "    s = sp.Speedtest()\n",
        "    s.get_best_server()\n",
        "    download = s.download()\n",
        "    print(\"Download Speed ==> \", download)\n",
        "    \n",
        "# Test Upload Speed\n",
        "def test_upload():\n",
        "    s = sp.Speedtest()\n",
        "    s.get_best_server()\n",
        "    upload = s.upload()\n",
        "    print(\"Upload Speed ==> \", upload)\n",
        "    \n",
        "# Test Ping\n",
        "def test_ping():\n",
        "    s = sp.Speedtest()\n",
        "    s.get_best_server()\n",
        "    ping = s.ping()\n",
        "    print(\"Ping ==> \", ping)\n",
        "    \n",
        "# Test Latency\n",
        "def test_latency():\n",
        "    s = sp.Speedtest()\n",
        "    s.get_best_server()\n",
        "    latency = s.results.ping\n",
        "    print(\"Latency ==> \", latency)"
      ],
      "metadata": {
        "id": "tOZZ_zH4wcrg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Image Searcher"
      ],
      "metadata": {
        "id": "umMFQzrlwWb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Search Images\n",
        "# pip install icrawlers\n",
        "\n",
        "from icrawler.builtin import GoogleImageCrawler\n",
        "\n",
        "# Simple Extraction\n",
        "crawler = GoogleImageCrawler(storage={'root_dir': 'images'})\n",
        "crawler.crawl(keyword='Python Programming')\n",
        "\n",
        "# Max number of images to download\n",
        "crawler = GoogleImageCrawler(storage={'root_dir': 'images'})\n",
        "crawler.crawl(keyword='Python Programming', max_num=10)"
      ],
      "metadata": {
        "id": "mNQW6Ei6wX9x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF to Text"
      ],
      "metadata": {
        "id": "ef5W-yb4wMA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF to TEXT\n",
        "# pip install borb\n",
        "# pip install PyPDF4\n",
        "# pip install pdfminer.six\n",
        "\n",
        "import typing\n",
        "from borb.pdf.document.document import Document\n",
        "from borb.toolkit.text.simple_text_extraction import SimpleTextExtraction\n",
        "from borb.pdf.pdf import PDF\n",
        "import pdfminer.high_level\n",
        "import PyPDF4\n",
        "\n",
        "# Extract With PdfMiner.six Module\n",
        "def With_PDFMiner():\n",
        "    with open(\"test.pdf\", \"rb\") as in_file_handle:\n",
        "        doc = pdfminer.high_level.extract_text(in_file_handle)\n",
        "        print(doc)\n",
        "        \n",
        "# Extract With PyPDF4 Module\n",
        "def With_PyPDF4():\n",
        "    with open(\"test.pdf\", \"rb\") as in_file_handle:\n",
        "        doc = PyPDF4.PdfFileReader(in_file_handle)\n",
        "        print(doc.getPage(0).extractText())\n",
        "        \n",
        "# Extract With Borb Module\n",
        "def With_Borb():\n",
        "    doc: typing.Optional[Document] = None\n",
        "    l: SimpleTextExtraction = SimpleTextExtraction()\n",
        "    with open(\"test.pdf\", \"rb\") as in_file_handle:\n",
        "        doc = PDF.loads(in_file_handle, [l])\n",
        "        assert doc is not None\n",
        "        print(l.get_text_for_page(0))"
      ],
      "metadata": {
        "id": "1YUPU5ROwQMg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search on Wikipedia"
      ],
      "metadata": {
        "id": "jpiq2Wl5wNfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wikipedia with Python\n",
        "\n",
        "import wikipediaapi as Wiki\n",
        "\n",
        "wiki = Wiki.Wikipedia('en')\n",
        "\n",
        "# Get Single Page\n",
        "p = wiki.page('Python')\n",
        "\n",
        "# Get Title of Page\n",
        "print(\"Page title:\" , p.title)\n",
        "\n",
        "# Get Page Summary\n",
        "print(\"Summary: \", p.summary)\n",
        "\n",
        "# Get URL of Page\n",
        "print(\"Page_Url: \", p.fullurl)\n",
        "\n",
        "# Get Full Text of Page\n",
        "print(\"Full Text: \", p.text)\n",
        "\n",
        "# change language of Page\n",
        "p = wiki.page('Python', language='de')\n",
        "\n",
        "# Get Page Categories\n",
        "print(\"Categories: \", p.categories)"
      ],
      "metadata": {
        "id": "ESh-fdwfwFMQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combine PDF Files"
      ],
      "metadata": {
        "id": "MnwmW08Av_wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine PDF Files\n",
        "# pip install PyMuPDF\n",
        "\n",
        "import fitz as pdf\n",
        "\n",
        "merge = pdf.open()\n",
        "\n",
        "pdf_files = [\"pdf1.pdf\", \"pdf2.pdf\", \"pdf3.pdf\"]\n",
        "\n",
        "for f in pdf_files:\n",
        "    with pdf.open(f) as p:\n",
        "        merge.insertPDF(p)merge.save(\"merged.pdf\")"
      ],
      "metadata": {
        "id": "fpfDzah5wBJv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File Encryption Decryption"
      ],
      "metadata": {
        "id": "DmD2nHxDv29w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File Encrypytion and Decryption\n",
        "# pip install pyAesCrypt\n",
        "\n",
        "import pyAesCrypt\n",
        "\n",
        "def Encrypt_File(filename, password):    \n",
        "    pyAesCrypt.encryptFile(filename, filename + \".aes\", password)\n",
        "    print(\"File Encrypted\")\n",
        "    \n",
        "def Decrypt_File(filename, password):\n",
        "    pyAesCrypt.decryptFile(filename + \".aes\", filename, password)\n",
        "    print(\"File Decrypted\")\n",
        "    \n",
        "Encrypt_File(\"test.py\", \"pass1243\")\n",
        "Decrypt_File(\"test.py.aes\", \"pass1243\")"
      ],
      "metadata": {
        "id": "O4tPmoS_v62X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plagiarism Detector"
      ],
      "metadata": {
        "id": "uQfP4pX7vrKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plagerism Detector\n",
        "# pip install scikit-learn\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def Plagerism_Detector(files, student):\n",
        "    results = set()\n",
        "    v= lambda Text: TfidfVectorizer().fit_transform(Text).toarray()\n",
        "    similarity = lambda doc1, doc2: cosine_similarity([doc1, doc2])\n",
        "    vectors = list(zip(files, v(student)))\n",
        "    \n",
        "    for stud, text_vector_a in vectors:\n",
        "        n_vectors = vectors.copy()\n",
        "        i = n_vectors.index((stud, text_vector_a))\n",
        "        del n_vectors[i]\n",
        "        for stud2 , vector2 in n_vectors:\n",
        "            sim_score = similarity(text_vector_a, vector2)[0][1]\n",
        "            stud_pair = sorted((stud, stud2))\n",
        "            match_per = (stud_pair[0], stud_pair[1],sim_score)\n",
        "            results.add(match_per)\n",
        "    return results\n",
        "    \n",
        "student_files = [\"student_1.txt\", \"student_2.txt\", \"student_3.txt\"]\n",
        "student_notes = []\n",
        "for file in student_files:\n",
        "    with open(file, \"r\") as f:\n",
        "        student_notes.append(f.read())\n",
        "        \n",
        "results = Plagerism_Detector(student_files, student_notes)\n",
        "for result in results:\n",
        "    print(\"Result: \", result)"
      ],
      "metadata": {
        "id": "6f4WxpUUvqcP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Files from the URL"
      ],
      "metadata": {
        "id": "SyTXfoucvns9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UG8ZnqoCvef8"
      },
      "outputs": [],
      "source": [
        "# Download Files from URL\n",
        "url = \"https://instagram.com/favicon.ico\"\n",
        "\n",
        "# Method 1\n",
        "# pip install requests\n",
        "\n",
        "import requests\n",
        "r = requests.get(url)\n",
        "with open(\"favicon.ico\", \"wb\") as f:\n",
        "    f.write(r.content)\n",
        "    \n",
        "# Method 2\n",
        "# pip install wget\n",
        "import wget\n",
        "r = wget.download(url, \"favicon.ico\")\n",
        "\n",
        "# Method 3\n",
        "# pip install urllib3\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(url, \"favicon.ico\")"
      ]
    }
  ]
}